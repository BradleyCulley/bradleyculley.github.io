I think AI will automate all, or almost all jobs at about the same time. In other words, a step-change profile for the technological singularity.

Reasoning:
-I think the different jobs people do are fundamentally not that computationally distinct. Being a lawyer versus being a construction worker versus being an engineer.

Further evidence, in both AIs and humans, is what in AI is called “transfer learning”. It's easier for an engineer to become a doctor, than it is for a random person to do so. The same for engineer -> lawyer, even.

-The jobs humans do have already been optimized around the parts of the computational universe (the ruliad) that are currently unautomatable. As we've automated more, to date there's paradoxically been more to do. Joseph Schumpeter's "Creative destruction" and David Frederick Schloss' "Lump of Labor Fallacy". Those aren't actual laws of nature though. Landauer's Principle and connectionism on the other hand, are. Moore's Law, Chinchilla scaling laws, and Huang's Law may as well be laws of nature, for now at least.

-The pieces that are unautomatable tend to require what AI scientists call "grounding". In other words, real understanding. ChatGPT isn't grounded. For example, ChatGPT can't accurately multiply large numbers. The technical terminology is "intensivity versus extensivity", or "distributional shift".

This isn't a John Henry thing...of course you can multiply them with a calculator. The point is that it doesn't actually understand multiplication. Not yet anyway.

-This is similar to/a variant of Moravec's Paradox. What's easy for a human is hard for an AI. "It is comparatively easy to make computers exhibit adult level performance on intelligence tests or playing checkers, and difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility" (https://lnkd.in/eetDKci6).

-Fully-autonomous self-driving has been predicted for years, yet still isn't here. Ability to use AI to augment one’s work and increase productivity is real. However, that’s not replacement/singularity.

-I've noticed a lot of opinions on the matter simply leave it there. Moravec's Paradox, real-world understanding, etc.: there is no singularity. I think there will be a singularity. The cortex has approximately the volume of a softball. It can't be that hard (understatement). In other words, AI will replace all jobs, but do so
for all of them at about the same time. Step-change.

-Coming at it from the other side, neural net architectures are converging. Transformers are effective in broader and broader problem domains. Karpathy has a good thread about this: tinyurl.com/26vc6b36. Brains use a single architecture for all these different problem domains, why wouldn't AI? There's even evidence (Nature paper!) of brains doing something roughly similar to next-token prediction: tinyurl.com/y88vne6n.

I think it’ll be a species-level cross-profession transition, with a fairly concise timeline
